{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_ieCl8uLeG3o"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Roboflow API를 통한 방법"
      ],
      "metadata": {
        "id": "_ieCl8uLeG3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##환경 설정 및 라이브러리 설치"
      ],
      "metadata": {
        "id": "DHqXxqOt_G26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx8rn2F4-_Q3"
      },
      "outputs": [],
      "source": [
        "!pip install inference-sdk\n",
        "!pip install pytesseract\n",
        "!apt-get install tesseract-ocr\n",
        "!apt-get install libtesseract-dev\n",
        "!pip install opencv-python-headless\n",
        "!pip install networkx\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Roboflow API 설정\n",
        "\n",
        "https://roboflow.com/"
      ],
      "metadata": {
        "id": "CWuxy9s7_KcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from inference_sdk import InferenceHTTPClient\n",
        "\n",
        "API_KEY = \"your_api_key_here\"\n",
        "CLIENT = InferenceHTTPClient(api_url=\"https://infer.roboflow.com\", api_key=API_KEY)"
      ],
      "metadata": {
        "id": "IAIx7D6E_B5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##모델 ID 정의"
      ],
      "metadata": {
        "id": "Ik4YM5SA_UbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOM_MODEL_ID = \"floor-plan-rendering/room-segmentation-model/1\"  # 버전 확인 필요\n",
        "WALL_MODEL_ID = \"iiitbangalore/floor-plan-segmentation-dtr4r/1\"  # 버전 확인 필요"
      ],
      "metadata": {
        "id": "mhcUwQV1_D8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##이미지 로드 및 인퍼런스 함수 정의"
      ],
      "metadata": {
        "id": "TZIlHonX_Wqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 로드 함수\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_image(path):\n",
        "    return cv2.imread(path)"
      ],
      "metadata": {
        "id": "0al_1JbO_FFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인퍼런스 실행 함수\n",
        "def run_inference(image_path, model_id):\n",
        "    result = CLIENT.infer(image_path, model_id=model_id)\n",
        "    return result"
      ],
      "metadata": {
        "id": "vxFXFwhF_fLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##텍스트 추출 함수 정의"
      ],
      "metadata": {
        "id": "qz2_aWkB_kzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "\n",
        "def extract_text(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    text_data = pytesseract.image_to_data(gray, lang='kor', output_type=pytesseract.Output.DICT)\n",
        "    return text_data"
      ],
      "metadata": {
        "id": "YgF_qVuS_msq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##방 번호 할당 함수 정의"
      ],
      "metadata": {
        "id": "Sa9tP4mY_oo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_room_numbers(room_masks, text_data):\n",
        "    room_labels = {}\n",
        "    for i, mask in enumerate(room_masks):\n",
        "        for j in range(len(text_data['text'])):\n",
        "            if text_data['text'][j].strip():\n",
        "                x = text_data['left'][j]\n",
        "                y = text_data['top'][j]\n",
        "                if mask[y, x]:  # 마스크 내 텍스트 확인\n",
        "                    room_labels[i] = text_data['text'][j]\n",
        "                    break\n",
        "    return room_labels"
      ],
      "metadata": {
        "id": "WnIJ930a_pvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##JSON 기반 그래프 로드 함수 정의"
      ],
      "metadata": {
        "id": "p-rGIwE8_uGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import json\n",
        "\n",
        "def load_graph_from_json(json_path, floor):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    G = nx.Graph()\n",
        "    for item in data:\n",
        "        if \"id\" in item:\n",
        "            node_id = f\"{floor}_{item['id']}\"\n",
        "            G.add_node(node_id, name=item['name'], type=item['type'], x=item['x'], y=item['y'], floor=floor)\n",
        "        elif \"source\" in item:\n",
        "            source = f\"{floor}_{item['source']}\"\n",
        "            target = f\"{floor}_{item['target']}\"\n",
        "            G.add_edge(source, target, weight=item['weight'])\n",
        "    return G"
      ],
      "metadata": {
        "id": "igpWnN5h_tjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##이미지 기반 그래프 생성 함수 정의"
      ],
      "metadata": {
        "id": "4Sb6Ycvk_xph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_graph_from_image(image_path, floor):\n",
        "    image = load_image(image_path)\n",
        "    room_result = run_inference(image_path, ROOM_MODEL_ID)\n",
        "    wall_result = run_inference(image_path, WALL_MODEL_ID)\n",
        "\n",
        "    # 방 마스크 추출 (예시, 실제 결과 형식에 따라 조정 필요)\n",
        "    room_masks = [pred['mask'] for pred in room_result['predictions'] if pred['class'] == 'room']\n",
        "    wall_masks = [pred['mask'] for pred in wall_result['predictions'] if pred['class'] == 'wall']\n",
        "\n",
        "    wall_mask = np.zeros(image.shape[:2], dtype=bool)\n",
        "    for mask in wall_masks:\n",
        "        wall_mask |= mask\n",
        "    open_space_mask = ~wall_mask\n",
        "\n",
        "    text_data = extract_text(image)\n",
        "    room_labels = assign_room_numbers(room_masks, text_data)\n",
        "\n",
        "    stair_positions = [(text_data['left'][i], text_data['top'][i], text) for i, text in enumerate(text_data['text']) if 'stair' in text.lower()]\n",
        "    elevator_positions = [(text_data['left'][i], text_data['top'][i], text) for i, text in enumerate(text_data['text']) if 'elevator' in text.lower()]\n",
        "\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # 방 노드 추가\n",
        "    room_nodes = []\n",
        "    for i, mask in enumerate(room_masks):\n",
        "        M = cv2.moments(mask.astype(np.uint8))\n",
        "        cx = int(M['m10'] / M['m00']) if M['m00'] != 0 else 0\n",
        "        cy = int(M['m01'] / M['m00']) if M['m00'] != 0 else 0\n",
        "        name = room_labels.get(i, f\"Room_{i}\")\n",
        "        node_id = f\"{floor}_room_{i}\"\n",
        "        G.add_node(node_id, name=name, type='Room', x=cx, y=cy, floor=floor)\n",
        "        room_nodes.append(node_id)\n",
        "\n",
        "    # 계단 및 엘리베이터 노드 추가\n",
        "    for i, (x, y, text) in enumerate(stair_positions):\n",
        "        node_id = f\"{floor}_stair_{i}\"\n",
        "        G.add_node(node_id, name=text, type='Stair', x=x, y=y, floor=floor)\n",
        "    for i, (x, y, text) in enumerate(elevator_positions):\n",
        "        node_id = f\"{floor}_elevator_{i}\"\n",
        "        G.add_node(node_id, name=text, type='Elevator', x=x, y=y, floor=floor)\n",
        "\n",
        "    # 그리드 노드 추가\n",
        "    grid_spacing = 20\n",
        "    height, width = image.shape[:2]\n",
        "    grid_nodes = []\n",
        "    for i in range(0, height, grid_spacing):\n",
        "        for j in range(0, width, grid_spacing):\n",
        "            if open_space_mask[i, j]:\n",
        "                node_id = f\"{floor}_grid_{i}_{j}\"\n",
        "                G.add_node(node_id, name='Corridor', type='Corridor', x=j, y=i, floor=floor)\n",
        "                grid_nodes.append(node_id)\n",
        "\n",
        "    # 인접 그리드 노드 연결\n",
        "    for node in grid_nodes:\n",
        "        x = G.nodes[node]['x']\n",
        "        y = G.nodes[node]['y']\n",
        "        neighbors = [(x + grid_spacing, y), (x - grid_spacing, y), (x, y + grid_spacing), (x, y - grid_spacing)]\n",
        "        for nx, ny in neighbors:\n",
        "            if 0 <= ny < height and 0 <= nx < width and open_space_mask[ny, nx]:\n",
        "                neighbor_id = f\"{floor}_grid_{ny}_{nx}\"\n",
        "                if neighbor_id in G.nodes:\n",
        "                    distance = np.sqrt((x - nx)**2 + (y - ny)**2)\n",
        "                    G.add_edge(node, neighbor_id, weight=distance)\n",
        "\n",
        "    # 방 노드와 가장 가까운 그리드 노드 연결\n",
        "    for room_node in room_nodes:\n",
        "        rx, ry = G.nodes[room_node]['x'], G.nodes[room_node]['y']\n",
        "        min_distance = float('inf')\n",
        "        nearest_grid = None\n",
        "        for grid_node in grid_nodes:\n",
        "            gx, gy = G.nodes[grid_node]['x'], G.nodes[grid_node]['y']\n",
        "            distance = np.sqrt((rx - gx)**2 + (ry - gy)**2)\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                nearest_grid = grid_node\n",
        "        if nearest_grid:\n",
        "            G.add_edge(room_node, nearest_grid, weight=min_distance)\n",
        "\n",
        "    # 계단 및 엘리베이터 노드와 가장 가까운 그리드 노드 연결 (동일)\n",
        "    for node_type in ['Stair', 'Elevator']:\n",
        "        for node in [n for n in G.nodes if G.nodes[n]['type'] == node_type and G.nodes[n]['floor'] == floor]:\n",
        "            x, y = G.nodes[node]['x'], G.nodes[node]['y']\n",
        "            min_distance = float('inf')\n",
        "            nearest_grid = None\n",
        "            for grid_node in grid_nodes:\n",
        "                gx, gy = G.nodes[grid_node]['x'], G.nodes[grid_node]['y']\n",
        "                distance = np.sqrt((x - gx)**2 + (y - gy)**2)\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    nearest_grid = grid_node\n",
        "            if nearest_grid:\n",
        "                G.add_edge(node, nearest_grid, weight=min_distance)\n",
        "\n",
        "    # 그래프 저장\n",
        "    with open(f'/content/drive/MyDrive/G{floor}.pkl', 'wb') as f:\n",
        "        pickle.dump(G, f)\n",
        "    return G"
      ],
      "metadata": {
        "id": "eq7KjeSo_yzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1~3층 JSON 기반 그래프 로드"
      ],
      "metadata": {
        "id": "Pa7sJI78_2ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G1 = load_graph_from_json('/content/drive/MyDrive/1f.json', 1)\n",
        "G2 = load_graph_from_json('/content/drive/MyDrive/2f.json', 2)\n",
        "G3 = load_graph_from_json('/content/drive/MyDrive/3f.json', 3)\n",
        "\n",
        "# 저장\n",
        "with open('/content/drive/MyDrive/G1.pkl', 'wb') as f:\n",
        "    pickle.dump(G1, f)\n",
        "with open('/content/drive/MyDrive/G2.pkl', 'wb') as f:\n",
        "    pickle.dump(G2, f)\n",
        "with open('/content/drive/MyDrive/G3.pkl', 'wb') as f:\n",
        "    pickle.dump(G3, f)"
      ],
      "metadata": {
        "id": "neW1-sDv_7Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##그래프 통합 및 층 간 연결"
      ],
      "metadata": {
        "id": "HPhQMD_L_-HK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 로드 (저장된 파일 사용)\n",
        "with open('/content/drive/MyDrive/G1.pkl', 'rb') as f:\n",
        "    G1 = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/G2.pkl', 'rb') as f:\n",
        "    G2 = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/G3.pkl', 'rb') as f:\n",
        "    G3 = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/G4.pkl', 'rb') as f:\n",
        "    G4 = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/G5.pkl', 'rb') as f:\n",
        "    G5 = pickle.load(f)\n",
        "\n",
        "G = nx.compose_all([G1, G2, G3, G4, G5])\n",
        "\n",
        "# 층 간 연결 추가\n",
        "from collections import defaultdict\n",
        "stair_nodes = [node for node in G.nodes if G.nodes[node]['type'] == 'Stair']\n",
        "elevator_nodes = [node for node in G.nodes if G.nodes[node]['type'] == 'Elevator']\n",
        "\n",
        "stair_groups = defaultdict(list)\n",
        "for node in stair_nodes:\n",
        "    name = G.nodes[node]['name']\n",
        "    parts = name.split('_')\n",
        "    if len(parts) == 2 and parts[1].endswith('f'):\n",
        "        stair_id = parts[0].replace('stair', '')\n",
        "        floor = int(parts[1][:-1])\n",
        "        stair_groups[stair_id].append((node, floor))\n",
        "\n",
        "for group in stair_groups.values():\n",
        "    group.sort(key=lambda x: x[1])\n",
        "    for i in range(len(group) - 1):\n",
        "        node1, node2 = group[i][0], group[i+1][0]\n",
        "        G.add_edge(node1, node2, weight=50)\n",
        "\n",
        "elevator_groups = defaultdict(list)\n",
        "for node in elevator_nodes:\n",
        "    name = G.nodes[node]['name']\n",
        "    parts = name.split('_')\n",
        "    if len(parts) == 2 and parts[1].endswith('f'):\n",
        "        elevator_id = parts[0].replace('elevator', '')\n",
        "        floor = int(parts[1][:-1])\n",
        "        elevator_groups[elevator_id].append((node, floor))\n",
        "\n",
        "for group in elevator_groups.values():\n",
        "    group.sort(key=lambda x: x[1])\n",
        "    for i in range(len(group) - 1):\n",
        "        node1, node2 = group[i][0], group[i+1][0]\n",
        "        G.add_edge(node1, node2, weight=20)\n",
        "\n",
        "# 저장\n",
        "with open('/content/drive/MyDrive/final_G.pkl', 'wb') as f:\n",
        "    pickle.dump(G, f)"
      ],
      "metadata": {
        "id": "x0fHeDLt__LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##경로 탐색 함수 정의 및 실행"
      ],
      "metadata": {
        "id": "dzRbaoLOAEDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 탐색 함수 정의\n",
        "with open('/content/drive/MyDrive/final_G.pkl', 'rb') as f:\n",
        "    G = pickle.load(f)\n",
        "\n",
        "room_to_node = {G.nodes[node]['name']: node for node in G.nodes if G.nodes[node]['type'] == 'Room'}\n",
        "\n",
        "def find_path(start_room, end_room):\n",
        "    start_node = room_to_node.get(start_room)\n",
        "    end_node = room_to_node.get(end_room)\n",
        "    if start_node and end_node:\n",
        "        path = nx.shortest_path(G, source=start_node, target=end_node, weight='weight')\n",
        "        simplified_path = [node for node in path if G.nodes[node]['type'] != 'Corridor']\n",
        "        path_names = [G.nodes[node]['name'] for node in simplified_path]\n",
        "        return \" -> \".join(path_names)\n",
        "    return \"강의실을 찾을 수 없습니다.\""
      ],
      "metadata": {
        "id": "OFGXind5AFUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 입력 및 경로 출력\n",
        "start_room = input(\"시작 강의실 입력 (예: 27508A): \")\n",
        "end_room = input(\"도착 강의실 입력 (예: 25108): \")\n",
        "result = find_path(start_room, end_room)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "lA2qKVzyAIhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mask R-CNN 사용 방법"
      ],
      "metadata": {
        "id": "gyNKeX0weLft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경 설정"
      ],
      "metadata": {
        "id": "ceySY1QreRAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html\n",
        "!pip install opencv-python-headless pytesseract networkx\n",
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr libtesseract-dev\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JGegYgoreSQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##학습 데이터 준비"
      ],
      "metadata": {
        "id": "a8nNebvceSou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import pytesseract\n",
        "from detectron2.structures import BoxMode\n",
        "import os\n",
        "\n",
        "def get_floorplan_dicts(img_dir, json_dir):\n",
        "    dataset_dicts = []\n",
        "    categories = {\"Room\": 0, \"Corridor\": 1, \"Stair\": 2, \"Elevator\": 3, \"Restroom\": 4, \"Door\": 5}\n",
        "\n",
        "    for floor in [1, 2, 3]:\n",
        "        img_path = os.path.join(img_dir, f\"{floor}.jpg\")\n",
        "        json_path = os.path.join(json_dir, f\"{floor}.json\")\n",
        "        image = cv2.imread(img_path)\n",
        "        height, width = image.shape[:2]\n",
        "\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # 이미지 전처리: 벽과 복도 식별\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # 노드와 컨투어 매핑\n",
        "        annotations = []\n",
        "        for node in [item for item in data if \"id\" in item]:\n",
        "            x, y = node['x'], node['y']\n",
        "            for contour in contours:\n",
        "                if cv2.pointPolygonTest(contour, (x, y), False) >= 0:\n",
        "                    x, y, w, h = cv2.boundingRect(contour)\n",
        "                    poly = contour.reshape(-1, 2).tolist()\n",
        "                    annotations.append({\n",
        "                        \"bbox\": [x, y, x+w, y+h],\n",
        "                        \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                        \"segmentation\": [poly],\n",
        "                        \"category_id\": categories[node['type']],\n",
        "                        \"id\": node['id']\n",
        "                    })\n",
        "                    break\n",
        "\n",
        "        # 텍스트 추출 및 매핑\n",
        "        text_data = pytesseract.image_to_data(image, lang='kor', output_type=pytesseract.Output.DICT)\n",
        "        for i, text in enumerate(text_data['text']):\n",
        "            if text.strip():\n",
        "                x, y = text_data['left'][i], text_data['top'][i]\n",
        "                for ann in annotations:\n",
        "                    bbox = ann['bbox']\n",
        "                    if bbox[0] <= x <= bbox[2] and bbox[1] <= y <= bbox[3]:\n",
        "                        ann['room_label'] = text\n",
        "                        break\n",
        "\n",
        "        dataset_dicts.append({\n",
        "            \"file_name\": img_path,\n",
        "            \"image_id\": floor,\n",
        "            \"height\": height,\n",
        "            \"width\": width,\n",
        "            \"annotations\": annotations\n",
        "        })\n",
        "\n",
        "    # 데이터셋 저장\n",
        "    with open('/content/drive/MyDrive/floorplan_dataset.json', 'w') as f:\n",
        "        json.dump(dataset_dicts, f)\n",
        "    return dataset_dicts\n",
        "\n",
        "# 데이터셋 등록\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "DatasetCatalog.register(\"floorplan_train\", lambda: get_floorplan_dicts('/content/drive/MyDrive/images', '/content/drive/MyDrive/json'))\n",
        "MetadataCatalog.get(\"floorplan_train\").set(thing_classes=[\"Room\", \"Corridor\", \"Stair\", \"Elevator\", \"Restroom\", \"Door\"])"
      ],
      "metadata": {
        "id": "dd3VPJHTeVJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mask R-CNN 학습"
      ],
      "metadata": {
        "id": "_9Hu4uGhebCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"floorplan_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6\n",
        "\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n",
        "\n",
        "# 모델 저장\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/model_final.pth'\n",
        "with open('/content/drive/MyDrive/model_config.yaml', 'w') as f:\n",
        "    f.write(cfg.dump())"
      ],
      "metadata": {
        "id": "JI_2BIjsedTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그래프 생성"
      ],
      "metadata": {
        "id": "HnmbCWeMed1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultPredictor\n",
        "import networkx as nx\n",
        "import pickle\n",
        "\n",
        "def build_graph_from_image(image_path, floor, cfg):\n",
        "    image = cv2.imread(image_path)\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "    outputs = predictor(image)\n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "    text_data = pytesseract.image_to_data(image, lang='kor', output_type=pytesseract.Output.DICT)\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # 노드 추가\n",
        "    for i, (mask, cls) in enumerate(zip(instances.pred_masks, instances.pred_classes)):\n",
        "        mask = mask.numpy()\n",
        "        M = cv2.moments(mask.astype(np.uint8))\n",
        "        cx = int(M['m10'] / M['m00']) if M['m00'] != 0 else 0\n",
        "        cy = int(M['m01'] / M['m00']) if M['m00'] != 0 else 0\n",
        "        node_id = f\"{floor}_{i}\"\n",
        "        class_name = [\"Room\", \"Corridor\", \"Stair\", \"Elevator\", \"Restroom\", \"Door\"][cls]\n",
        "\n",
        "        # 텍스트 매핑\n",
        "        name = f\"{class_name}_{i}\"\n",
        "        for j, text in enumerate(text_data['text']):\n",
        "            if text.strip():\n",
        "                x = text_data['left'][j] + text_data['width'][j] // 2\n",
        "                y = text_data['top'][j] + text_data['height'][j] // 2\n",
        "                if mask[y, x]:\n",
        "                    name = text\n",
        "                    break\n",
        "        G.add_node(node_id, name=name, type=class_name, x=cx, y=cy, floor=floor)\n",
        "\n",
        "    # 복도 마스크로 그리드 노드 생성\n",
        "    corridor_mask = np.zeros(image.shape[:2], dtype=bool)\n",
        "    for i, (mask, cls) in enumerate(zip(instances.pred_masks, instances.pred_classes)):\n",
        "        if cls == 1:  # Corridor\n",
        "            corridor_mask |= mask.numpy()\n",
        "\n",
        "    grid_spacing = 20\n",
        "    height, width = image.shape[:2]\n",
        "    grid_nodes = []\n",
        "    for i in range(0, height, grid_spacing):\n",
        "        for j in range(0, width, grid_spacing):\n",
        "            if corridor_mask[i, j]:\n",
        "                node_id = f\"{floor}_grid_{i}_{j}\"\n",
        "                G.add_node(node_id, name='Corridor', type='Corridor', x=j, y=i, floor=floor)\n",
        "                grid_nodes.append(node_id)\n",
        "\n",
        "    # 그리드 노드 연결\n",
        "    for node in grid_nodes:\n",
        "        x = G.nodes[node]['x']\n",
        "        y = G.nodes[node]['y']\n",
        "        neighbors = [(x + grid_spacing, y), (x - grid_spacing, y), (x, y + grid_spacing), (x, y - grid_spacing)]\n",
        "        for nx, ny in neighbors:\n",
        "            if 0 <= ny < height and 0 <= nx < width and corridor_mask[ny, nx]:\n",
        "                neighbor_id = f\"{floor}_grid_{ny}_{nx}\"\n",
        "                if neighbor_id in G.nodes:\n",
        "                    distance = np.sqrt((x - nx)**2 + (y - ny)**2)\n",
        "                    G.add_edge(node, neighbor_id, weight=distance)\n",
        "\n",
        "    # 방, 문, 계단 등과 복도 연결\n",
        "    for node in G.nodes:\n",
        "        if G.nodes[node]['type'] in ['Room', 'Door', 'Stair', 'Elevator', 'Restroom']:\n",
        "            x, y = G.nodes[node]['x'], G.nodes[node]['y']\n",
        "            min_distance = float('inf')\n",
        "            nearest_grid = None\n",
        "            for grid_node in grid_nodes:\n",
        "                gx, gy = G.nodes[grid_node]['x'], G.nodes[grid_node]['y']\n",
        "                distance = np.sqrt((x - gx)**2 + (y - gy)**2)\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    nearest_grid = grid_node\n",
        "            if nearest_grid:\n",
        "                G.add_edge(node, nearest_grid, weight=min_distance)\n",
        "\n",
        "    # 그래프 저장\n",
        "    with open(f'/content/drive/MyDrive/G{floor}.pkl', 'wb') as f:\n",
        "        pickle.dump(G, f)\n",
        "    return G\n",
        "\n",
        "# 4~5층 그래프 생성\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file('/content/drive/MyDrive/model_config.yaml')\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/model_final.pth'\n",
        "G4 = build_graph_from_image('/content/drive/MyDrive/4.jpg', 4, cfg)\n",
        "G5 = build_graph_from_image('/content/drive/MyDrive/5.jpg', 5, cfg)"
      ],
      "metadata": {
        "id": "waoed2fzeg0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그래프 통합 + 층간 연결"
      ],
      "metadata": {
        "id": "uD-BrTrVeiVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "# 그래프 로드\n",
        "with open('/content/drive/MyDrive/G1.pkl', 'rb') as f:\n",
        "    G1 = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/G2.pkl', 'rb') as f:\n",
        "    G2 = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/G3.pkl', 'rb') as f:\n",
        "    G3 = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/G4.pkl', 'rb') as f:\n",
        "    G4 = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/G5.pkl', 'rb') as f:\n",
        "    G5 = pickle.load(f)\n",
        "\n",
        "G = nx.compose_all([G1, G2, G3, G4, G5])\n",
        "\n",
        "# 층 간 연결\n",
        "stair_nodes = [node for node in G.nodes if G.nodes[node]['type'] == 'Stair']\n",
        "elevator_nodes = [node for node in G.nodes if G.nodes[node]['type'] == 'Elevator']\n",
        "\n",
        "stair_groups = defaultdict(list)\n",
        "for node in stair_nodes:\n",
        "    name = G.nodes[node]['name']\n",
        "    parts = name.split('_')\n",
        "    if len(parts) == 2 and parts[1].endswith('f'):\n",
        "        stair_id = parts[0].replace('stair', '')\n",
        "        floor = int(parts[1][:-1])\n",
        "        stair_groups[stair_id].append((node, floor))\n",
        "\n",
        "for group in stair_groups.values():\n",
        "    group.sort(key=lambda x: x[1])\n",
        "    for i in range(len(group) - 1):\n",
        "        node1, node2 = group[i][0], group[i+1][0]\n",
        "        G.add_edge(node1, node2, weight=50)\n",
        "\n",
        "elevator_groups = defaultdict(list)\n",
        "for node in elevator_nodes:\n",
        "    name = G.nodes[node]['name']\n",
        "    parts = name.split('_')\n",
        "    if len(parts) == 2 and parts[1].endswith('f'):\n",
        "        elevator_id = parts[0].replace('elevator', '')\n",
        "        floor = int(parts[1][:-1])\n",
        "        elevator_groups[elevator_id].append((node, floor))\n",
        "\n",
        "for group in elevator_groups.values():\n",
        "    group.sort(key=lambda x: x[1])\n",
        "    for i in range(len(group) - 1):\n",
        "        node1, node2 = group[i][0], group[i+1][0]\n",
        "        G.add_edge(node1, node2, weight=20)\n",
        "\n",
        "# 최종 그래프 저장\n",
        "with open('/content/drive/MyDrive/final_G.pkl', 'wb') as f:\n",
        "    pickle.dump(G, f)"
      ],
      "metadata": {
        "id": "aOcXbCZcekpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 경로 탐색"
      ],
      "metadata": {
        "id": "MdeqyWL6eoCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/final_G.pkl', 'rb') as f:\n",
        "    G = pickle.load(f)\n",
        "\n",
        "room_to_node = {G.nodes[node]['name']: node for node in G.nodes if G.nodes[node]['type'] == 'Room'}\n",
        "\n",
        "def find_path(start_room, end_room):\n",
        "    start_node = room_to_node.get(start_room)\n",
        "    end_node = room_to_node.get(end_room)\n",
        "    if start_node and end_node:\n",
        "        path = nx.shortest_path(G, source=start_node, target=end_node, weight='weight')\n",
        "        simplified_path = [node for node in path if G.nodes[node]['type'] != 'Corridor']\n",
        "        path_names = [G.nodes[node]['name'] for node in simplified_path]\n",
        "        return \" -> \".join(path_names)\n",
        "    return \"강의실을 찾을 수 없습니다.\"\n",
        "\n",
        "start_room = input(\"시작 강의실 입력 (예: 27508A): \")\n",
        "end_room = input(\"도착 강의실 입력 (예: 25108): \")\n",
        "result = find_path(start_room, end_room)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Oy8A_AcpepRa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}